---
title: Introduction
description: Comprehensive observability for your LLM applications with OpenTelemetry-based tracing
---

## What is Laminar Tracing?

Laminar offers comprehensive observability for your LLM applications, capturing the entire execution flow with minimal setup. This allows you to:

- **Debug complex Agents and LLM workflows** by seeing exactly how data flows through your application
- **Monitor performance** with detailed execution time and token usage metrics
- **Track costs** across different models and components
- **Analyze user sessions** to understand and improve the end-user experience

## Key Concepts

### Span

A single operation in your application's execution flow, such as a function call or an API request. Spans include:

- **Attributes**: Input parameters, return values, and other metadata
- **Path**: Hierarchical location in your code (e.g., `get_user.validate.api_call`)
- **Duration**: How long the operation took to execute

### Trace

A collection of spans that form a complete execution path. Traces show parent-child relationships between operations, helping you understand how your code executes.

### Session

A group of related traces belonging to the same user interaction or conversation, allowing you to analyze complete user journeys.

### Visualization Example

<div style={{ border: '1px solid #2B2B30', borderRadius: '8px', overflow: 'hidden' }}>
<img src="/images/traces/trace-example.png" alt="Screenshot of a trace visualization" style={{ margin: '0px' }}/>
</div>

The tree view on the left shows a trace of an LLM application. The hierarchy displays how functions call each other:
- `answer_question` calls `fetch_page_and_check`
- which calls `check_presence` 
- which calls `OpenAI`

Each node in this tree is a span, giving you a complete picture of your application's execution.

## What Laminar Captures

For every execution of your application, Laminar automatically records:

### Performance Metrics
- Total execution time
- Per-span execution times
- Bottlenecks and slow operations

### LLM-Specific Data
- Token counts (input and output)
- Model information
- Cost calculations

### Inputs & Outputs
- Function parameters
- Return values
- Prompts and completions

### Execution Flow
- Parent-child relationships
- Complete call hierarchy
- Cross-service transactions

<div style={{ border: '1px solid #2B2B30', borderRadius: '8px', overflow: 'hidden' }}>
<img src="/images/traces/trace-attr.png" alt="Screenshot of trace attributes" style={{ margin: '0px' }}/>
</div>






## Next Steps

Now that you understand the basics of Laminar tracing:

- Get started quickly with our [Quickstart Guide](/tracing/quickstart)
- Explore our integrations to see how Laminar works with your favorite tools:
    - [OpenAI](/tracing/integrations/openai)
    - [Anthropic](/tracing/integrations/anthropic)
    - [Gemini](/tracing/integrations/gemini)
    - [Langchain](/tracing/integrations/langchain)
    - [Next.js](/tracing/integrations/nextjs)
    - [Vercel AI SDK](/tracing/integrations/vercel-ai-sdk)
    - [LiteLLM](/tracing/integrations/litellm)
    - [Playwright](/tracing/integrations/playwright)
    - [Puppeteer](/tracing/integrations/puppeteer)
    - [Browser Use](/tracing/integrations/browser-use)
    - [Stagehand](/tracing/integrations/stagehand)
- Continue to [Trace Structure](/tracing/structure) to learn more about how to add structure to your traces
- Explore [Browser agent observability](/tracing/browser-agent-observability) to learn how to record browser sessions and sync them with agent execution steps

---
title: Trace Vercel AI SDK calls
sidebarTitle: Vercel AI SDK
---
import GetProjectApiKey from '/snippets/get-project-api-key.mdx';

Trace `generateText`/`streamText` calls with Laminar’s OpenTelemetry tracer. You’ll see prompts, responses, tokens, and costs with no app rewrites.

<Frame>
  <img src="/images/traces/vercel-ai-sdk-example.png" alt="Vercel AI SDK trace with prompt and cost" />
</Frame>

## What you'll build

- Traces for AI SDK calls with inputs/outputs and cost.  
- Works in Next.js and Node.js with minimal config.  
- Shareable trace links + Playground for prompt iteration.

## Copy/paste/run

<Steps>
<Step title="Get your project API key">
<GetProjectApiKey />
</Step>

<Step title="Initialize Laminar">
<Tabs>
<Tab title="Next.js">

`instrumentation.ts`:

```ts {3-4,6-8}
export async function register() {
  if (process.env.NEXT_RUNTIME === 'nodejs') {
    const { Laminar } = await import('@lmnr-ai/lmnr');
    Laminar.initialize({ projectApiKey: process.env.LMNR_PROJECT_API_KEY });
  }
}
```

`next.config.ts` (required for Laminar/OpenTelemetry):

```ts
const nextConfig = {
  serverExternalPackages: ['@lmnr-ai/lmnr'],
};
export default nextConfig;
```

</Tab>
<Tab title="Node.js">

```ts
import { Laminar } from '@lmnr-ai/lmnr';

Laminar.initialize({
  projectApiKey: process.env.LMNR_PROJECT_API_KEY,
});
```

</Tab>
</Tabs>
</Step>

<Step title="Trace your AI SDK calls">

```ts {3,8-11}
import { openai } from '@ai-sdk/openai';
import { generateText } from 'ai';
import { getTracer } from '@lmnr-ai/lmnr';

const { text } = await generateText({
  model: openai('gpt-4o-mini'),
  prompt: 'What is Laminar flow?',
  experimental_telemetry: {
    isEnabled: true,
    tracer: getTracer(),
  },
});

console.log(text);
```

</Step>
</Steps>

## What to look for

- Span name: `ai.generateText` (or `ai.streamText`) with prompt/response captured.  
- Tokens + cost per call; rollups if you wrap parents with `observe`.  
- Playground button on each span to tweak prompts.

## What just happened?

- Laminar tracer from `getTracer()` captures AI SDK calls without changing your app code.
- Prompts, responses, tokens, and cost flow to your Laminar project automatically.
- Traces link to Playgrounds for quick prompt iteration.

## Build this next

- Next.js app with OpenAI/Anthropic → [Next.js integration](/tracing/integrations/nextjs)  
- Tag spans for cost per route/team → [Tags and metadata](/tracing/structure/tags)  
- Compare model providers → [OpenAI](/tracing/integrations/openai) and [Anthropic](/tracing/integrations/anthropic)

---
title: Trace OpenAI in JS and Python (3 steps)
sidebarTitle: OpenAI
description: Copy/paste setup to see OpenAI calls with inputs, outputs, tokens, and cost.
---

Instrument OpenAI with a single import. You will get per-call traces with prompts, responses, latency, tokens, and cost, plus links to Playgrounds for fast iteration.

<Callout>
Embed placeholder: GIF of running the three commands and opening the OpenAI span with cost breakdown.
</Callout>

## What you'll build

- Traces for every OpenAI call (chat/completions) with inputs/outputs.  
- Token + cost tracking per call and rolled up.  
- Shareable trace links; open any span in Playground.

## Copy/paste/run

<Tabs items={['TypeScript', 'Python']}>
  <Tab title="TypeScript">

```bash
npm install @lmnr-ai/lmnr openai
```

Add one-line auto-instrumentation before your app code:

```ts
import 'lmnr/auto';
import { OpenAI } from 'openai';

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const res = await client.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [{ role: 'user', content: 'Hello from Laminar' }],
});

console.log(res.choices[0].message.content);
```

Run it:

```bash
LMNR_PROJECT_API_KEY=your_key node app.js
```

<Note>
Need explicit control? Replace the auto-import with `Laminar.initialize({ instrumentModules: { OpenAI } });`.
</Note>

  </Tab>
  <Tab title="Python">

```bash
pip install "lmnr[openai]" openai
```

Add one-line auto-instrumentation:

```python
import lmnr.auto
from openai import OpenAI
import os

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

resp = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello from Laminar"}],
)

print(resp.choices[0].message.content)
```

Run it:

```bash
LMNR_PROJECT_API_KEY=your_key python app.py
```

  </Tab>
</Tabs>

## What to look for in the trace

- Span name: `openai.chat.completions.create` (child of your function if wrapped with `observe`).  
- Inputs/outputs: full prompt and response.  
- Tokens/cost: per-call totals and rollups.  
- Playground button: jump into prompt editing directly from the span.

## Build this next

- Next.js + OpenAI recipe → [Next.js integration](/tracing/integrations/nextjs)  
- Vercel AI SDK → [Vercel AI SDK integration](/tracing/integrations/vercel-ai-sdk)  
- Compare providers with the same code → [Anthropic integration](/tracing/integrations/anthropic)  
- Add tags to break down cost → [Tags and metadata](/tracing/structure/tags)

---
title: LLM Observability for LiteLLM
sidebarTitle: LiteLLM
description: Configure LiteLLM to send traces to Laminar
---

## Overview

[LiteLLM](https://www.litellm.ai/) is a framework/library for building LLM applications that simplifies accessing many models across different providers.

## Default configuration

<Steps>
<Step title="Ensure you have the latest version of Laminar">
```sh
pip install -U lmnr[all]
```
</Step>
<Step title="Initialize Laminar and integrate the callback">
```python
import litellm
from lmnr import Laminar, LaminarLiteLLMCallback

# 1. Initialize Laminar
Laminar.initialize(project_api_key="LMNR_PROJECT_API_KEY")

# 2. Integrate the callback
litellm.callbacks = [LaminarLiteLLMCallback()]
```
</Step>
<Step title="Run your code and see traces in Laminar">

Example code:

```python
import litellm
from lmnr import Laminar, LaminarLiteLLMCallback

Laminar.initialize(project_api_key="LMNR_PROJECT_API_KEY")
litellm.callbacks = [LaminarLiteLLMCallback()]

response = litellm.completion(
    model="gpt-4.1-nano",
    messages=[
      {"role": "user", "content": "What is the capital of France?"}
    ],
)
```


<div style={{ border: '1px solid #2B2B30', borderRadius: '8px', overflow: 'hidden' }}>
  <img src="/images/traces/litellm.png" alt="LiteLLM trace" style={{ margin: '0px' }}/>
</div>
</Step>
</Steps>

### Disabling OpenAI double-instrumentation

If you use OpenAI, enabling Laminar LiteLLM callback may result in OpenAI calls being double-traced â€“ once by Laminar LiteLLM callback and once by Laminar auto-instrumentation.
This is because LiteLLM uses OpenAI SDK under the hood to call some of the models and Laminar automatically instruments OpenAI SDK.

To avoid this, you can disable OpenAI instrumentation at initialization:

```python {4}
from lmnr import Laminar, Instruments
Laminar.initialize(
  project_api_key="LMNR_PROJECT_API_KEY",
  disabled_instruments=set([Instruments.OPENAI])
)
```

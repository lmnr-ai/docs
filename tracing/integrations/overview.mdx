---
title: Integrations
sidebarTitle: Introduction
---

Laminar automatically traces calls to supported LLM providers, agent frameworks, and vector databases. You don't need to change your codeâ€”just initialize Laminar, and calls to OpenAI, Anthropic, LangChain, and others are captured with full details: prompts, responses, tokens, latency, and cost.

Browse the integrations below to see setup instructions and what's captured for each.

Don't see your provider? You can trace any LLM with the `@observe` decorator or by creating manual spans. See [Tracing Structure](/tracing/structure/overview) or jump straight to [observe usage](/tracing/structure/observe-decorator).

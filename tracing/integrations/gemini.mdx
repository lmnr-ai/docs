---
title: LLM Observability for Gemini SDK
sidebarTitle: Gemini
description: Instrument your Google Gemini API calls with Laminar
---

## Overview

Laminar automatically instruments the official Google Gemini package with a single line of code, allowing you to trace and monitor all your Gemini API calls without modifying your existing code. This provides complete visibility into your AI application's performance, costs, and behavior.

## Getting Started

### 1. Install Laminar and Google Gemini

```bash
pip install 'lmnr[all]' google-genai python-dotenv
```

<Note>
You may remove the `[all]` extra, and there is no specific extra for Gemini.
Gemini instrumentation is currently shipped with the default `lmnr` package.
</Note>

### 2. Set up your environment variables

Store your API keys in a `.env` file:

```bash
# .env file
LMNR_PROJECT_API_KEY=your-laminar-project-api-key
GEMINI_API_KEY=your-gemini-api-key
```

<Note>
To see an example of how to integrate Laminar within a FastAPI application, check out our [FastAPI integration guide](/guides/fastapi).
</Note>

### 3. Initialize Laminar

Just add a single line at the start of your application or file to instrument Gemini with Laminar.

```python
from lmnr import Laminar
from google import genai
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# This single line instruments all Gemini API calls
Laminar.initialize()

# Initialize Gemini client as usual
client = genai.Client(api_key=os.environ["GEMINI_API_KEY"])
```

### 4. Use Gemini as usual

```python
# Make API calls to Gemini as you normally would
response = client.models.generate_content(
    model="gemini-2.5-flash-preview-04-17",
    contents="Tell me a short story about a robot learning to paint."
)

print(response.text)
```

All Gemini API calls are now automatically traced in Laminar.

## Monitoring Your Gemini Usage

After instrumenting your Gemini calls with Laminar, you'll be able to:

1. **View detailed traces** of each Gemini API call, including request and response
2. **Track token usage and cost** across different models
3. **Monitor latency** and performance metrics
4. **Open LLM span in Playground** for prompt engineering
5. **Debug issues** with failed API calls or unexpected model outputs

Visit your Laminar dashboard to view your Gemini traces and analytics.

## Advanced Features

- [Sessions](/tracing/manual-instrumentation#sessions) - Learn how to add session structure to your traces
- [Metadata](/tracing/structure/metadata) - Discover how to add additional context to your LLM spans
- [Trace structure](/tracing/structure) - Explore creating custom spans and more advanced tracing
- [Realtime Monitoring](/tracing/realtime) - See how to monitor your Gemini calls in real-time

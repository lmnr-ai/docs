---
title: Extract signals using LLMs
---

LLM signals let you extract structured data that cannot be explicitly logged but can be inferred from trace data. You define a prompt that describes what to look for (for example, "Agent completes checkout process"), and Laminar sends the signal definition plus the `trace_id` to the semantic-event service. The service returns a structured payload that Laminar stores as a signal event linked to that trace.

## When to use LLM signals

- **Business outcomes** - Describe criteria for a successful outcome, for example "User responded with 'Thank you'".
- **Logical errors** - Describe a case when an agent fails to complete a task, for example "Agent fails to complete checkout process".
- **Behavioral patterns** - Categorize user requests by specifying "request category" in the structured output schema.

If you already log structured events in your application code, you do not need LLM signals for those.

## Create a signal (UI)

To define a new signal from trace data:

<Frame caption="Creating a new signal in the Laminar UI">
  <img src="/images/create-event.png" alt="Create new signal form showing name, prompt, structured output schema, and test trace" />
</Frame>

1. Open **Signals** and click **Create signal**.
2. (Optional) **Start from a template** to prefill the prompt and schema.
3. Fill in:
   - **Name**: choose a stable signal name (for example, `checkout.completed` or `navigation.failed`).
   - **Prompt**: describe what the signal should detect or extract from trace data.
   - **Structured Output**: define a JSON schema for the signal payload (keep it small and stable).
   - (Optional) **Test Signal**: enter a trace ID to validate the output before creating it.
4. Click **Create**.

## Run the signal on traces

Once the signal exists:

- Use **Jobs** to backfill a time range or filtered set of traces.
- Use **Triggers** to keep the signal running on new traces that match your trigger filters.

### Jobs (backfill)

Use a job when you want to run a signal against historical traces or a filtered slice of data.

How it works in the UI:
- Go to the signal's **Jobs** tab and click **Create Job**.
- Pick a **time range** (default is the last 24 hours).
- Add **filters** and/or **search** to narrow the trace set.
- Select either **specific traces** or **all traces matching your filters**.
- Click **Create signal job** to enqueue processing.

What to expect:
- A job creates one **run per trace**.
- Runs appear in the **Runs** tab with status (Pending, Completed, Failed).
- If the signal is identified, you will see an **Event ID** and the signal appears in the **Events** tab.
- If the signal is not identified, the run completes without an event.

### Triggers (live)

Use a trigger to run the signal automatically on new traces.

How it works in the UI:
- Go to the signal's **Triggers** tab and click **Add Trigger**.
- Add one or more **filters** (all conditions must match).
- The trigger runs on new traces that match those filters.

What to expect:
- Each matching trace creates a **run** with source "Trigger."
- Signal events appear in the **Events** tab when identified.


## Viewing signal events

In the Laminar dashboard:

<Frame caption="Viewing signal events in the Signals page">
  <img src="/images/view-events.png" alt="Signals events table with filters and trace links" />
</Frame>

1. Go to **Signals** and open your signal.
2. Use **Events** to see the raw event stream and jump to traces.
3. (Optional) Query signal events in the [SQL Editor](/platform/sql-editor) using the `signal_events` table.

Once you have LLM signals running, you can [cluster them](/tracing/events/clusters) to discover patterns and group similar events together.

---
title: Installation
description: Copy/paste installs to get your first Laminar trace fast.
---

Laminar is designed to get you to a live trace in minutes. Pick your language, run the three commands, and your LLM calls will show up with inputs, outputs, tokens, and costs.

## What you'll do

- Install Laminar alongside your model SDK.
- Add one import to auto-instrument.
- Run your existing code and open the trace.

## JavaScript/TypeScript

```bash
# 1) Install Laminar + OpenAI client
npm install @lmnr-ai/lmnr openai

# 2) One-line auto-instrumentation (import before app code)
echo "import 'lmnr/auto'" > bootstrap.ts

# 3) Run with your Laminar key
LMNR_PROJECT_API_KEY=your_key node app.js
```

<Tip>
Yarn: `yarn add @lmnr-ai/lmnr openai`  
pnpm: `pnpm add @lmnr-ai/lmnr openai`
</Tip>

## Python

```bash
# 1) Install Laminar + OpenAI client
pip install --upgrade "lmnr[openai]"

# 2) One-line auto-instrumentation
echo "import lmnr.auto" > bootstrap.py

# 3) Run with your Laminar key
LMNR_PROJECT_API_KEY=your_key python app.py
```

<Expandable title="Pick additional instrumentations (Python extras)">
Add extras to auto-trace specific SDKs. Examples:

- Anthropic + OpenAI: `pip install --upgrade "lmnr[anthropic,openai]"`
- LangChain + LlamaIndex: `pip install --upgrade "lmnr[langchain,llamaindex]"`
- Vector DBs (Pinecone, Weaviate, Qdrant): `pip install --upgrade "lmnr[pinecone,weaviate,qdrant]"`

Full extras list: alephalpha, anthropic, bedrock, cohere, google-generativeai, groq, haystack, lancedb, langchain, llamaindex, marqo, milvus, mistralai, ollama, openai, pinecone, qdrant, replicate, sagemaker, together, transformers, vertexai, watsonx, weaviate.
</Expandable>

<Frame>
  <img src="/images/traces/trace-example.png" alt="Laminar trace showing tokens and cost" />
</Frame>
